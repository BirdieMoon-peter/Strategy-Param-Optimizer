# -*- coding: utf-8 -*-
"""
é€šç”¨ä¼˜åŒ–å™¨è¿è¡Œè„šæœ¬
ä½¿ç”¨ç¤ºä¾‹å’Œå‘½ä»¤è¡Œæ¥å£
"""

import sys
import json
import argparse
from pathlib import Path

from universal_optimizer import UniversalOptimizer
from universal_llm_client import UniversalLLMConfig, PRESET_CONFIGS


def main():
    parser = argparse.ArgumentParser(
        description="é€šç”¨ç­–ç•¥ä¼˜åŒ–å™¨",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•ï¼ˆä¸ä½¿ç”¨LLMï¼‰
  python run_universal_optimizer.py --data data/BTC.csv --strategy strategies/my_strategy.py
  
  # ä½¿ç”¨OpenAI GPT-4
  python run_universal_optimizer.py --data data/BTC.csv --strategy strategies/my_strategy.py \\
      --use-llm --llm-type openai --llm-model gpt-4 --api-key sk-xxx
  
  # ä½¿ç”¨æœ¬åœ°Ollama
  python run_universal_optimizer.py --data data/BTC.csv --strategy strategies/my_strategy.py \\
      --use-llm --llm-type ollama --llm-model qwen
  
  # æ‰¹é‡ä¼˜åŒ–å¤šä¸ªç›®æ ‡
  python run_universal_optimizer.py --data data/BTC.csv --strategy strategies/my_strategy.py \\
      --batch --objectives sharpe_ratio annual_return calmar_ratio
  
  # æŒ‡å®šè¯•éªŒæ¬¡æ•°å’Œè¾“å‡ºç›®å½•
  python run_universal_optimizer.py --data data/BTC.csv --strategy strategies/my_strategy.py \\
      --trials 100 --output ./my_results
        """
    )
    
    # å¿…éœ€å‚æ•°
    parser.add_argument(
        "--data",
        required=True,
        help="æ ‡çš„æ•°æ®CSVæ–‡ä»¶è·¯å¾„"
    )
    parser.add_argument(
        "--strategy",
        required=True,
        help="ç­–ç•¥è„šæœ¬æ–‡ä»¶è·¯å¾„ï¼ˆ.pyæ–‡ä»¶ï¼‰"
    )
    
    # ä¼˜åŒ–å‚æ•°
    parser.add_argument(
        "--objective",
        default="sharpe_ratio",
        choices=[
            "sharpe_ratio", "annual_return", "total_return",
            "max_drawdown", "calmar_ratio", "sortino_ratio"
        ],
        help="ä¼˜åŒ–ç›®æ ‡ï¼ˆé»˜è®¤: sharpe_ratioï¼‰"
    )
    parser.add_argument(
        "--trials",
        type=int,
        default=50,
        help="ä¼˜åŒ–è¯•éªŒæ¬¡æ•°ï¼ˆé»˜è®¤: 50ï¼‰"
    )
    
    # LLMå‚æ•°
    parser.add_argument(
        "--use-llm",
        action="store_true",
        help="æ˜¯å¦ä½¿ç”¨LLMè¾…åŠ©ä¼˜åŒ–"
    )
    parser.add_argument(
        "--llm-type",
        choices=["openai", "ollama", "custom"],
        default="openai",
        help="LLMç±»å‹ï¼ˆé»˜è®¤: openaiï¼‰"
    )
    parser.add_argument(
        "--llm-model",
        default="gpt-4",
        help="LLMæ¨¡å‹åç§°ï¼ˆé»˜è®¤: gpt-4ï¼‰"
    )
    parser.add_argument(
        "--api-key",
        default="",
        help="APIå¯†é’¥ï¼ˆOpenAIæˆ–è‡ªå®šä¹‰APIéœ€è¦ï¼‰"
    )
    parser.add_argument(
        "--base-url",
        default="",
        help="APIåŸºç¡€URLï¼ˆå¯é€‰ï¼Œé»˜è®¤æ ¹æ®llm-typeè‡ªåŠ¨è®¾ç½®ï¼‰"
    )
    
    # æ‰¹é‡ä¼˜åŒ–
    parser.add_argument(
        "--batch",
        action="store_true",
        help="æ‰¹é‡ä¼˜åŒ–æ¨¡å¼ï¼ˆä¼˜åŒ–å¤šä¸ªç›®æ ‡ï¼‰"
    )
    parser.add_argument(
        "--objectives",
        nargs="+",
        default=["sharpe_ratio", "annual_return"],
        help="æ‰¹é‡ä¼˜åŒ–çš„ç›®æ ‡åˆ—è¡¨"
    )
    
    # è¾“å‡ºå‚æ•°
    parser.add_argument(
        "--output",
        default="./optimization_results",
        help="è¾“å‡ºç›®å½•ï¼ˆé»˜è®¤: ./optimization_resultsï¼‰"
    )
    parser.add_argument(
        "--quiet",
        action="store_true",
        help="é™é»˜æ¨¡å¼ï¼ˆä¸æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼‰"
    )
    
    args = parser.parse_args()
    
    # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not Path(args.data).exists():
        print(f"âŒ é”™è¯¯: æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.data}")
        return 1
    
    if not Path(args.strategy).exists():
        print(f"âŒ é”™è¯¯: ç­–ç•¥æ–‡ä»¶ä¸å­˜åœ¨: {args.strategy}")
        return 1
    
    # é…ç½®LLM
    llm_config = None
    if args.use_llm:
        # è®¾ç½®é»˜è®¤base_url
        if not args.base_url:
            if args.llm_type == "openai":
                base_url = "https://api.openai.com/v1"
            elif args.llm_type == "ollama":
                base_url = "http://localhost:11434"
            else:
                print("âŒ é”™è¯¯: ä½¿ç”¨customç±»å‹æ—¶å¿…é¡»æŒ‡å®š--base-url")
                return 1
        else:
            base_url = args.base_url
        
        llm_config = UniversalLLMConfig(
            api_type=args.llm_type,
            base_url=base_url,
            model_name=args.llm_model,
            api_key=args.api_key,
            temperature=0.7
        )
        
        if not args.quiet:
            print(f"ğŸ¤– LLMé…ç½®:")
            print(f"   ç±»å‹: {args.llm_type}")
            print(f"   æ¨¡å‹: {args.llm_model}")
            print(f"   URL: {base_url}")
            print()
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    try:
        optimizer = UniversalOptimizer(
            data_path=args.data,
            strategy_path=args.strategy,
            objective=args.objective,
            use_llm=args.use_llm,
            llm_config=llm_config,
            output_dir=args.output,
            verbose=not args.quiet
        )
    except Exception as e:
        print(f"âŒ åˆ›å»ºä¼˜åŒ–å™¨å¤±è´¥: {e}")
        return 1
    
    # æ‰§è¡Œä¼˜åŒ–
    try:
        if args.batch:
            # æ‰¹é‡ä¼˜åŒ–
            print(f"\nğŸš€ å¼€å§‹æ‰¹é‡ä¼˜åŒ–ï¼ˆç›®æ ‡: {', '.join(args.objectives)}ï¼‰\n")
            result = optimizer.batch_optimize(
                objectives=args.objectives,
                n_trials_per_objective=args.trials
            )
        else:
            # å•ç›®æ ‡ä¼˜åŒ–
            print(f"\nğŸš€ å¼€å§‹ä¼˜åŒ–ï¼ˆç›®æ ‡: {args.objective}ï¼‰\n")
            result = optimizer.optimize(n_trials=args.trials)
        
        # æ‰“å°æ‘˜è¦
        if not args.quiet:
            print("\n" + "="*60)
            print("âœ… ä¼˜åŒ–å®Œæˆï¼")
            print("="*60)
            
            if args.batch:
                print(f"\næ‰¹é‡ä¼˜åŒ–ç»“æœæ‘˜è¦:")
                for obj, obj_result in result.get("results", {}).items():
                    metrics = obj_result.get("performance_metrics", {})
                    print(f"\nç›®æ ‡: {obj}")
                    print(f"  å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 'N/A')}")
                    print(f"  å¹´åŒ–æ”¶ç›Š: {metrics.get('annual_return', 'N/A')}%")
                    print(f"  æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 'N/A')}%")
            else:
                metrics = result.get("performance_metrics", {})
                params = result.get("best_parameters", {})
                
                print(f"\næœ€ä¼˜å‚æ•°:")
                for key, value in params.items():
                    print(f"  {key}: {value}")
                
                print(f"\næ€§èƒ½æŒ‡æ ‡:")
                print(f"  å¤æ™®æ¯”ç‡: {metrics.get('sharpe_ratio', 'N/A')}")
                print(f"  å¹´åŒ–æ”¶ç›Š: {metrics.get('annual_return', 'N/A')}%")
                print(f"  æœ€å¤§å›æ’¤: {metrics.get('max_drawdown', 'N/A')}%")
                print(f"  æ€»æ”¶ç›Šç‡: {metrics.get('total_return', 'N/A')}%")
                print(f"  äº¤æ˜“æ¬¡æ•°: {metrics.get('trades_count', 'N/A')}")
                print(f"  èƒœç‡: {metrics.get('win_rate', 'N/A')}%")
                
                # LLMè§£é‡Š
                if args.use_llm and "llm_explanation" in result:
                    explanation = result["llm_explanation"]
                    print(f"\nğŸ’¡ LLMåˆ†æ:")
                    print(f"  {explanation.get('parameter_explanation', '')}")
                    
                    if "key_insights" in explanation:
                        print(f"\nå…³é”®æ´å¯Ÿ:")
                        for insight in explanation["key_insights"]:
                            print(f"  â€¢ {insight}")
            
            print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜è‡³: {args.output}")
            print("="*60 + "\n")
        
        return 0
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ä¼˜åŒ–è¢«ç”¨æˆ·ä¸­æ–­")
        return 1
    except Exception as e:
        print(f"\nâŒ ä¼˜åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())
